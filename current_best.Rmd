---
title: "current best model"
author: "Jonathan Gill"
date: "April 25, 2018"
output: html_document
---

glmfinal has not yet been tested on kaggle, but seems to be an improvement on glm1 (based on splitting the training data). glm1 was created by eliminating in one step all insignificant variables from the full model. glmfinal contains two variables more than glm1, which were determined by anova (2-3 least significant variables eliminated at a time, starting from the full model).

If we are submitting a glm as our final model, it should be glmfinal, not glm1.
Both these models use na.convert.mean.


Convert NAs
```{r}
na.convert.mean = function (frame) 
{
    vars <- names(frame)
    if (!is.null(resp <- attr(attr(frame, "terms"), "response"))) {
        vars <- vars[-resp]
        x <- frame[[resp]]
        pos <- is.na(x)
        if (any(pos)) {
            frame <- frame[!pos, , drop = FALSE]
            warning(paste(sum(pos), "observations omitted due to missing values in the response"))
        }
    }
    for (j in vars) {  #j is variable names
        x <- frame[[j]]
        pos <- is.na(x)
        if (any(pos)) {
            if (length(levels(x))) {   # factors
                xx <- as.character(x)
                xx[pos] <- "NA"
                x <- factor(xx, exclude = NULL)
            }
            else if (is.matrix(x)) {   # matrices
                ats <- attributes(x)
                x.na <- 1*pos
#               x[pos] <- 0
                w <- !pos
                n <- nrow(x)
                TT <- array(1, c(1, n))
                xbar <- (TT %*% x)/(TT %*% w)
                xbar <- t(TT) %*% xbar
                x[pos] <- xbar[pos]
                attributes(x) <- ats
                attributes(x.na) <- ats
                dimnames(x.na)[[2]]=paste(dimnames(x)[[2]],".na",sep='')
                frame[[paste(j,".na",sep='')]] <- x.na 
            } else {   # ordinary numerical vector
                ats <- attributes(x)
                x[pos] <- mean(x[!pos])
#               x[pos] <- 0
                x.na <- 1*pos
                frame[[paste(j,".na",sep='')]] <- x.na 
                attributes(x) <- ats
            }
            frame[[j]] <- x
        }
    }
    frame
}




train = read.csv("train.csv")

train_convert_na = na.convert.mean(train)

#Converting relevant variables to factors
cols1 = c(2,3,4,5,6,8,11,12,14:45,48)
train_convert_na[cols1] = lapply(train_convert_na[cols1], factor)

#removing aliased columns
train_convert_na = train_convert_na[,-which(names(train_convert_na) %in% c("density_rural","single"))]

glm_na_convert = glm(suppdem~ . , family = binomial(), data = train_convert_na)
summary(glm_na_convert)
```



Build model with significant coefficients only (shouldnt be eliminating so many variables at the same time, but for now this is our best)
```{r}
glm1 = glm(suppdem~ density_suburban + density_urban + sex + combined_ethnicity_4way + combined_ethnicity_4way + ppi + married + education+ hasreligion + catholic + christian + interest_in_religion + donrever_1 + liberal_donor + conservative_donor + contbrel_1 + apparel_1+cat_1+guns_1 + cnty_pct_religious + cnty_pct_evangelical + cnty_pct_religious.na + cnty_pct_evangelical.na, family = binomial(), data = train_convert_na)
```


Using anova, we find including the number of children and the outdoor indicator is an improvement on glm1. The rest of the variables don't seem to help.
```{r}
glmfinal = glm(suppdem~ density_suburban + density_urban + sex + combined_ethnicity_4way + combined_ethnicity_4way + ppi + married + education+ hasreligion + catholic + christian + interest_in_religion + donrever_1 + liberal_donor + conservative_donor + contbrel_1 + apparel_1+cat_1+guns_1 + cnty_pct_religious + cnty_pct_evangelical + cnty_pct_religious.na + cnty_pct_evangelical.na
           
            + num_children +outdoor_1 
            
           , family = binomial(), data = train_convert_na) 
```


Testing within the train dataset
```{r}
na.convert.mean = function (frame) 
{
    vars <- names(frame)
    if (!is.null(resp <- attr(attr(frame, "terms"), "response"))) {
        vars <- vars[-resp]
        x <- frame[[resp]]
        pos <- is.na(x)
        if (any(pos)) {
            frame <- frame[!pos, , drop = FALSE]
            warning(paste(sum(pos), "observations omitted due to missing values in the response"))
        }
    }
    for (j in vars) {  #j is variable names
        x <- frame[[j]]
        pos <- is.na(x)
        if (any(pos)) {
            if (length(levels(x))) {   # factors
                xx <- as.character(x)
                xx[pos] <- "NA"
                x <- factor(xx, exclude = NULL)
            }
            else if (is.matrix(x)) {   # matrices
                ats <- attributes(x)
                x.na <- 1*pos
#               x[pos] <- 0
                w <- !pos
                n <- nrow(x)
                TT <- array(1, c(1, n))
                xbar <- (TT %*% x)/(TT %*% w)
                xbar <- t(TT) %*% xbar
                x[pos] <- xbar[pos]
                attributes(x) <- ats
                attributes(x.na) <- ats
                dimnames(x.na)[[2]]=paste(dimnames(x)[[2]],".na",sep='')
                frame[[paste(j,".na",sep='')]] <- x.na 
            } else {   # ordinary numerical vector
                ats <- attributes(x)
                x[pos] <- mean(x[!pos])
#               x[pos] <- 0
                x.na <- 1*pos
                frame[[paste(j,".na",sep='')]] <- x.na 
                attributes(x) <- ats
            }
            frame[[j]] <- x
        }
    }
    frame
}




train = read.csv("train.csv")

train_convert_na = na.convert.mean(train)

#Converting relevant variables to factors
cols1 = c(2,3,4,5,6,8,11,12,14:45,48)
train_convert_na[cols1] = lapply(train_convert_na[cols1], factor)

#removing aliased columns
train_convert_na = train_convert_na[,-which(names(train_convert_na) %in% c("density_rural","single"))]

train  = train_convert_na

#split dataset
set.seed = 1
samp = sample.int(n = nrow(train), size = 3000, replace = F)
testsub = train[samp, ]
trainsub = train[-samp,]

glmfinal = glm(suppdem~ density_suburban + density_urban + sex + combined_ethnicity_4way + combined_ethnicity_4way + ppi + married + education+ hasreligion + catholic + christian + interest_in_religion + donrever_1 + liberal_donor + conservative_donor + contbrel_1 + apparel_1+cat_1+guns_1 + cnty_pct_religious + cnty_pct_evangelical + cnty_pct_religious.na + cnty_pct_evangelical.na
           
            + num_children +outdoor_1 
            
           , family = binomial(), data = trainsub)
#testing
predictions = predict(glmfinal, na.roughfix(testsub), type = "response")

#change response from factor to binary
test_binary = ifelse(testsub$suppdem=="Y", 1, 0)
d = -(1/nrow(testsub))*sum((test_binary *log(predictions) + (1-test_binary )*log(1-predictions)))
d


#now compare to previous model
glm1 = glm(suppdem~ density_suburban + density_urban + sex + combined_ethnicity_4way + combined_ethnicity_4way + ppi + married + education+ hasreligion + catholic + christian + interest_in_religion + donrever_1 + liberal_donor + conservative_donor + contbrel_1 + apparel_1+cat_1+guns_1 + cnty_pct_religious + cnty_pct_evangelical + cnty_pct_religious.na + cnty_pct_evangelical.na, family = binomial(), data = trainsub)
#testing
predictions = predict(glm1, na.roughfix(testsub), type = "response")

#change response from factor to binary
test_binary = ifelse(testsub$suppdem=="Y", 1, 0)
d2 = -(1/nrow(testsub))*sum((test_binary *log(predictions) + (1-test_binary )*log(1-predictions)))
d2
```



Prediction
```{r}
test = read.csv("test.csv")
test.converted = na.convert.mean(test)

#Converting relevant variables to factors
cols1 = c(2,3,4,5,6,8,11,12,14:45,48)
test.converted[cols1] = lapply(test.converted[cols1], factor)
out = predict(glm3, test.converted, type = "response")
write.csv(out, "predictions.csv")
```
