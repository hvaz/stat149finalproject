---
title: "Stat 149 Final Project: Team Theoretical Limit"
author: "Eduardo Cesar, Jonathan Gill, Sean Murphy and Henrique Vaz"
fontsize: 11pt
geometry: margin=0.5in

output:
  pdf_document:
    includes:
      in_header: pset_header.tex
    fig_width: 6.5
    fig_height: 4.5
---
\newcommand{\noin}{\noindent}    
\newcommand{\Var}{\text{Var}} 
\newcommand{\Bin}{\text{Bin}}
\newcommand{\Bern}{\text{Bern}}
\newcommand{\Beta}{\text{Beta}}
\newcommand{\Cov}{\text{Cov}}    
\newcommand{\bs}{\boldsymbol}
\newcommand{\mb}{\mathbf}
\newcommand{\ansl}{\textcolor{blue}}

#LIBRARIES
```{r, include=FALSE, cache=FALSE}
library(car)
library(MASS)
library(stats)
```


#Cleaning data and initial diagnostics
Cleaning data and finding collinearity: 
1. testing for and removing (after step 3) aliased variables
2. removing NA cases
3. converting variables to factors
4. converting the response variable to binary, running OLS regression
5. computing VIFs based on the OLS
6. Find columns with NA values ("age", "education", "cnty_pct_religious", "cnty_pct_evangelical")

```{r}
train = read.csv("train.csv")

#find columns with NA values
colnames(train)[colSums(is.na(train)) > 0]

#population densities (train$density_rural+train$density_suburban+train$density_urban)
densitytest = train$density_rural+train$density_suburban+train$density_urban 
#Aliased. Should remove 1 or collapse to categorical
sum(densitytest) == length(densitytest)

#marital status
marriagetest = train$married + train$single 
#All but 7 observations sum to 1. Treat as perfectly correlated
max(marriagetest)
sum(marriagetest)==length(marriagetest)

#home ownership
hometest = train$homeowner+train$renter 
#around 350 people are neither homeowners nor renters; let's hang on to both variables
sum(hometest)
length(hometest)

#removing missing
train_no_na = train[complete.cases(train), ]

#Converting relevant variables to factors
cols1 = c(2,3,4,5,6,8,11,12,14:45,48)
train_no_na[cols1] = lapply(train_no_na[cols1], factor)

#removing aliased columns
train_no_na = train_no_na[,-which(names(train_no_na) %in% c("density_rural","single"))]

train_no_na$suppdem = ifelse(train_no_na$suppdem=="Y", 1, 0)

#took out density_rural, single, and homeowner
ols = lm(suppdem ~ ., data = train_no_na)
vif(ols)
```


#Building GLM with NAs removed dataframe
Using the data with NA rows removed, build a GLM with all variables
```{r}
full_model_remove = glm(suppdem~ . , family = binomial(), data = train_no_na)
```


#Building GLM with NAs converted to means dataframe
1.Using convert to mean function from lecture
2. reload dataset, clean and convert NAs
3. build full GLM
*Note big coeffient changes for ppi, married, num_children, outdgrdn_11, and outdoor_11
```{r}
na.convert.mean = function (frame)
{
    vars <- names(frame)
    if (!is.null(resp <- attr(attr(frame, "terms"), "response"))) {
        vars <- vars[-resp]
        x <- frame[[resp]]
        pos <- is.na(x)
        if (any(pos)) {
            frame <- frame[!pos, , drop = FALSE]
            warning(paste(sum(pos), "observations omitted due to missing values in the response"))
        }
    }
    for (j in vars) {  #j is variable names
        x <- frame[[j]]
        pos <- is.na(x)
        if (any(pos)) {
            if (length(levels(x))) {   # factors
                xx <- as.character(x)
                xx[pos] <- "NA"
                x <- factor(xx, exclude = NULL)
            }
            else if (is.matrix(x)) {   # matrices
                ats <- attributes(x)
                x.na <- 1*pos
#               x[pos] <- 0
                w <- !pos
                n <- nrow(x)
                TT <- array(1, c(1, n))
                xbar <- (TT %*% x)/(TT %*% w)
                xbar <- t(TT) %*% xbar
                x[pos] <- xbar[pos]
                attributes(x) <- ats
                attributes(x.na) <- ats
                dimnames(x.na)[[2]]=paste(dimnames(x)[[2]],".na",sep='')
                frame[[paste(j,".na",sep='')]] <- x.na
            } else {   # ordinary numerical vector
                ats <- attributes(x)
                x[pos] <- mean(x[!pos])
#               x[pos] <- 0
                x.na <- 1*pos
                frame[[paste(j,".na",sep='')]] <- x.na
                attributes(x) <- ats
            }
            frame[[j]] <- x
        }
    }
    frame
}

train_convert_na = na.convert.mean(train)

#Converting relevant variables to factors
cols1 = c(2,3,4,5,6,8,11,12,14:45,48)
train_convert_na[cols1] = lapply(train_convert_na[cols1], factor)

#removing aliased columns
train_convert_na = train_convert_na[,-which(names(train_convert_na) %in% c("density_rural","single"))]

fullmodel_mean_convert = glm(suppdem~ . , family = binomial(), data = train_convert_na)

#Compare summaries of full models from both the na removed data set and the na converted mean data set
summary(fullmodel_mean_convert)
summary(full_model_remove)
```


#Model building and anova comparison
1. start with only the variables that were significant in the full model
2. add in other coefficients

adding num_children improves on the model

Note: adding age alone improves on the model, but adding age + age.na does not make a significant improvement over adding neither.
```{r}
#significant coefficients only 
glm1 = glm(suppdem~ density_suburban + density_urban + sex + combined_ethnicity_4way + combined_ethnicity_4way + ppi + married + education+ hasreligion + catholic + christian + interest_in_religion + donrever_1 + liberal_donor + conservative_donor + contbrel_1 + apparel_1+cat_1+guns_1 + cnty_pct_religious + cnty_pct_evangelical + cnty_pct_religious.na + cnty_pct_evangelical.na, family = binomial(), data = train_convert_na) 

glm2 = glm(suppdem~ density_suburban + density_urban + sex + combined_ethnicity_4way + combined_ethnicity_4way + ppi + married + education+ hasreligion + catholic + christian + interest_in_religion + donrever_1 + liberal_donor + conservative_donor + contbrel_1 + apparel_1+cat_1+guns_1 + cnty_pct_religious + cnty_pct_evangelical + cnty_pct_religious.na + cnty_pct_evangelical.na +age + age.na + party_reg_state + party_primary_state + + census_median_income, family = binomial(), data = train_convert_na)


glm3 = glm(suppdem~ density_suburban + density_urban + sex + combined_ethnicity_4way + combined_ethnicity_4way + ppi + married + education+ hasreligion + catholic + christian + interest_in_religion + donrever_1 + liberal_donor + conservative_donor + contbrel_1 + apparel_1+cat_1+guns_1 + cnty_pct_religious + cnty_pct_evangelical + cnty_pct_religious.na + cnty_pct_evangelical.na + num_children, family = binomial(), data = train_convert_na)

glm4 = glm(suppdem~ density_suburban + density_urban + sex + combined_ethnicity_4way + combined_ethnicity_4way + ppi + married + education+ hasreligion + catholic + christian + interest_in_religion + donrever_1 + liberal_donor + conservative_donor + contbrel_1 + apparel_1+cat_1+guns_1 + cnty_pct_religious + cnty_pct_evangelical + cnty_pct_religious.na + cnty_pct_evangelical.na+ num_children, family = binomial(), data = train_convert_na)

anova(glm1, glm2,  test = "Chisq")
```

<!-- #Stepwise AIC and BIC -->
<!-- 1. mention this was taken from stat 139... -->
<!-- ```{r} -->
<!-- glm_na_convert = glm(suppdem~ . , family = binomial(), data = train_convert_na) -->
<!-- intercept = glm(suppdem~1,family = binomial(), data = train_convert_na) -->

<!-- aicmodel = step(intercept, scope = list(upper = glm_na_convert), direction = "forward", k = 2 ) -->

<!-- summary(aicmodel) -->

<!-- ``` -->

# Clean Test Data and Predictions
```{r}
test = read.csv("test.csv")
test.converted = na.convert.mean(test)

#Clean test data
cols1 = c(2,3,4,5,6,8,11,12,14:45,48)
test.converted[cols1] = lapply(test.converted[cols1], factor)

#Predict on AIC MODEL
# out = predict(aicmodel, test.converted)
# write.csv(out, "predictions.csv")
```



